gam2a=gam(I(wage>250)~s(age,df=4)+year+education,data=Wage,family=binomial)
anova(gam2a,gam2,test="Chisq")
par(mfrow=c(1,3))
lm1=lm(wage~ns(age,df=4)+ns(year,df=4)+education,data=Wage)
plot.gam(lm1,se=T)
```{r}
# Chunk 1
require(ISLR)
attach(Wage)
# Chunk 2
fit=lm(wage~poly(age,4),data=Wage)
summary(fit)
# Chunk 3
agelims=range(age)
age.grid=seq(from=agelims[1],to=agelims[2])
preds=predict(fit,newdata=list(age=age.grid),se=TRUE)
se.bands=cbind(preds$fit+2*preds$se,preds$fit-2*preds$se)
plot(age,wage,col="darkgrey")
lines(age.grid,preds$fit,lwd=2,col="blue")
matlines(age.grid,se.bands,col="blue",lty=2)
# Chunk 4
fita=lm(wage~age+I(age^2)+I(age^3)+I(age^4),data=Wage)
summary(fita)
# Chunk 5
plot(fitted(fit),fitted(fita))
# Chunk 6
summary(fit)
# Chunk 7
fita=lm(wage~education,data=Wage)
fitb=lm(wage~education+age,data=Wage)
fitc=lm(wage~education+poly(age,2),data=Wage)
fitd=lm(wage~education+poly(age,3),data=Wage)
anova(fita,fitb,fitc,fitd)
# Chunk 8
fit=glm(I(wage>250) ~ poly(age,3), data=Wage, family=binomial)
summary(fit)
preds=predict(fit,list(age=age.grid),se=T)
se.bands=preds$fit + cbind(fit=0,lower=-2*preds$se,upper=2*preds$se)
se.bands[1:5,]
# Chunk 9
prob.bands=exp(se.bands)/(1+exp(se.bands))
matplot(age.grid,prob.bands,col="blue",lwd=c(2,1,1),lty=c(1,2,2),type="l",ylim=c(0,.1))
points(jitter(age),I(wage>250)/10,pch="|",cex=.5)
# Chunk 10
require(splines)
fit=lm(wage~bs(age,knots=c(25,40,60)),data=Wage)
plot(age,wage,col="darkgrey")
lines(age.grid,predict(fit,list(age=age.grid)),col="darkgreen",lwd=2)
abline(v=c(25,40,60),lty=2,col="darkgreen")
# Chunk 11
fit=smooth.spline(age,wage,df=16)
lines(fit,col="red",lwd=2)
# Chunk 12
fit=smooth.spline(age,wage,cv=TRUE)
lines(fit,col="purple",lwd=2)
fit
# Chunk 13
require(gam)
gam1=gam(wage~s(age,df=4)+s(year,df=4)+education,data=Wage)
par(mfrow=c(1,3))
plot(gam1,se=T)
gam2=gam(I(wage>250)~s(age,df=4)+s(year,df=4)+education,data=Wage,family=binomial)
plot(gam2)
# Chunk 14
gam2a=gam(I(wage>250)~s(age,df=4)+year+education,data=Wage,family=binomial)
anova(gam2a,gam2,test="Chisq")
# Chunk 15
par(mfrow=c(1,3))
lm1=lm(wage~ns(age,df=4)+ns(year,df=4)+education,data=Wage)
plot.gam(lm1,se=T)
`7.R` <- read.table("C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/7.R.RData", quote="\"")
View(`7.R`)
View(prob.bands)
require(ISLR)
attach(Wage)
require(ISLR)
require(tree)
attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
install.packages("tree")
require(ISLR)
require(tree)
attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
View(Carseats)
tree.carseats=tree(High~.-Sales,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
require(ISLR)
require(tree)
attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
tree.carseats=tree(High~.-Sales,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats=tree(High~.,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats=tree(High~.-Sales,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats=tree(High~.s,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats=tree(High~.,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
require(ISLR)
require(tree)
attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
tree.carseats=tree(High~.-Sales,data=Carseats)
summary(tree.carseats)
plot(tree.carseats)
text(tree.carseats,pretty=0)
tree.carseats
set.seed(1011)
train=sample(1:nrow(Carseats),250)
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
plot(tree.carseats);text(tree.carseats,pretty=0)
tree.pred=predict(tree.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(72+33)/150
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
cv.carseats
plot(cv.carseats)
prune.carseats=prune.misclass(tree.carseats,best=13)
plot(prune.carseats);text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats[-train,],type="class")
with(Carseats[-train,],table(tree.pred,High))
(72+32)/150
require(randomForest)
require(MASS)
set.seed(101)
dim(Boston)
train=sample(1:nrow(Boston),300)
?Boston
rf.boston=randomForest(medv~.,data=Boston,subset=train)
rf.boston
require(randomForest)
require(MASS)
set.seed(101)
dim(Boston)
train=sample(1:nrow(Boston),300)
?Boston
install.packages("randomForest")
require(randomForest)
require(MASS)
set.seed(101)
dim(Boston)
train=sample(1:nrow(Boston),300)
?Boston
rf.boston=randomForest(medv~.,data=Boston,subset=train)
rf.boston
oob.err=double(13)
test.err=double(13)
for(mtry in 1:13){
fit=randomForest(medv~.,data=Boston,subset=train,mtry=mtry,ntree=400)
oob.err[mtry]=fit$mse[400]
pred=predict(fit,Boston[-train,])
test.err[mtry]=with(Boston[-train,],mean((medv-pred)^2))
cat(mtry," ")
}
matplot(1:mtry,cbind(test.err,oob.err),pch=19,col=c("red","blue"),type="b",ylab="Mean Squared Error")
legend("topright",legend=c("OOB","Test"),pch=19,col=c("red","blue"))
require(gbm)
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
summary(boost.boston)
plot(boost.boston,i="lstat")
plot(boost.boston,i="rm")
install.packages("gbm")
require(gbm)
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
summary(boost.boston)
plot(boost.boston,i="lstat")
plot(boost.boston,i="rm")
require(gbm)
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
summary(boost.boston)
plot(boost.boston,i="lstat")
plot(boost.boston,i="rm")
install.packages("gbm")
require(gbm)
boost.boston=gbm(medv~.,data=Boston[train,],distribution="gaussian",n.trees=10000,shrinkage=0.01,interaction.depth=4)
summary(boost.boston)
plot(boost.boston,i="lstat")
plot(boost.boston,i="rm")
n.trees=seq(from=100,to=10000,by=100)
predmat=predict(boost.boston,newdata=Boston[-train,],n.trees=n.trees)
dim(predmat)
berr=with(Boston[-train,],apply( (predmat-medv)^2,2,mean))
plot(n.trees,berr,pch=19,ylab="Mean Squared Error", xlab="# Trees",main="Boosting Test Error")
abline(h=min(test.err),col="red")
SVM
set.seed(10111)
x=matrix(rnorm(40),20,2)
y=rep(c(-1,1),c(10,10))
x[y==1,]=x[y==1,]+1
plot(x,col=y+3,pch=19)
install.packages("e1071")
library(e1071)
dat=data.frame(x,y=as.factor(y))
svmfit=svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
print(svmfit)
plot(svmfit,dat)
make.grid=function(x,n=75){
grange=apply(x,2,range)
x1=seq(from=grange[1,1],to=grange[2,1],length=n)
x2=seq(from=grange[1,2],to=grange[2,2],length=n)
expand.grid(X1=x1,X2=x2)
}
xgrid=make.grid(x)
ygrid=predict(svmfit,xgrid)
plot(xgrid,col=c("red","blue")[as.numeric(ygrid)],pch=20,cex=.2)
points(x,col=y+3,pch=19)
points(x[svmfit$index,],pch=5,cex=2)
beta=drop(t(svmfit$coefs)%*%x[svmfit$index,])
beta0=svmfit$rho
plot(xgrid,col=c("red","blue")[as.numeric(ygrid)],pch=20,cex=.2)
points(x,col=y+3,pch=19)
points(x[svmfit$index,],pch=5,cex=2)
abline(beta0/beta[2],-beta[1]/beta[2])
abline((beta0-1)/beta[2],-beta[1]/beta[2],lty=2)
abline((beta0+1)/beta[2],-beta[1]/beta[2],lty=2)
load(url("http://www.stanford.edu/~hastie/ElemStatLearn/datasets/ESL.mixture.rda"))
names(ESL.mixture)
rm(x,y)
attach(ESL.mixture)
plot(x,col=y+1)
dat=data.frame(y=factor(y),x)
fit=svm(factor(y)~.,data=dat,scale=FALSE,kernel="radial",cost=5)
xgrid=expand.grid(X1=px1,X2=px2)
ygrid=predict(fit,xgrid)
plot(xgrid,col=as.numeric(ygrid),pch=20,cex=.2)
points(x,col=y+1,pch=19)
func=predict(fit,xgrid,decision.values=TRUE)
func=attributes(func)$decision
xgrid=expand.grid(X1=px1,X2=px2)
ygrid=predict(fit,xgrid)
plot(xgrid,col=as.numeric(ygrid),pch=20,cex=.2)
points(x,col=y+1,pch=19)
contour(px1,px2,matrix(func,69,99),level=0,add=TRUE)
contour(px1,px2,matrix(prob,69,99),level=.5,add=TRUE,col="blue",lwd=2)
set.seed(10111)
x=matrix(rnorm(40),20,2)
y=rep(c(-1,1),c(10,10))
x[y==1,]=x[y==1,]+1
plot(x,col=y+3,pch=19)
View(x)
x=matrix(rnorm(40),50,10)
x=matrix(rnorm(100),50,10)
x=matrix(rnorm(40),20,2)
y=rep(c(-1,1),c(10,10))
x[y==1,]=x[y==1,]+1
plot(x,col=y+3,pch=19)
set.seed(10111)
x=matrix(rnorm(40),20,2)
y=rep(c(-1,1),c(10,10))
x[y==1,]=x[y==1,]+1
plot(x,col=y+3,pch=19)
dimnames(USArrests)
apply(USArrests,2,mean)
apply(USArrests,2, var)
pca.out=prcomp(USArrests, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0)
pca.out=prcomp(USArrests, scale=TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale=0, cex=.6)
set.seed(101)
x=matrix(rnorm(100*2),100,2)
xmean=matrix(rnorm(8,sd=4),4,2)
which=sample(1:4,100,replace=TRUE)
x=x+xmean[which,]
plot(x,col=which,pch=19)
km.out=kmeans(x,4,nstart=15)
km.out
plot(x,col=km.out$cluster,cex=2,pch=1,lwd=2)
points(x,col=which,pch=19)
points(x,col=c(4,3,2,1)[which],pch=19)
hc.complete=hclust(dist(x),method="complete")
plot(hc.complete)
hc.single=hclust(dist(x),method="single")
plot(hc.single)
hc.average=hclust(dist(x),method="average")
plot(hc.average)
plot(hc.complete)
hc.cut=cutree(hc.complete,4)
table(hc.cut,which)
table(hc.cut,km.out$cluster)
plot(hc.complete,labels=which)
library(e1071)
View(x)
plot(x)
x=matrix(rnorm(100),50,10)
View(x)
plot(x)
set.seed(10111)
x=matrix(rnorm(40),20,2)
y=rep(c(-1,1),c(10,10))
x[y==1,]=x[y==1,]+1
plot(x,col=y+3,pch=19)
#for the indices where y=1, add the vector mu
library(e1071)
#generate data
set.seed(10111)
#generate 50 observations of x from R10. 500 total observations drawn from a normal distribution
x=matrix(rnorm(500),50,10)
y=rep(c(0,1),c(25,25))
y
x[y==1,]=x[y==1,]+c(1,1,1,1,1,0,0,0,0,0)
View(x)
dat=data.frame(x,y=as.factor(y))
View(dat)
plot(dat$X1,dat$X2 col=dat$y,pch=19)
plot(dat$X1,dat$X2, col=dat$y,pch=19)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
make.grid=function(x,n=75){
grange=apply(x,2,range)
x1=seq(from=grange[1,1],to=grange[2,1],length=n)
x2=seq(from=grange[1,2],to=grange[2,2],length=n)
expand.grid(X1=x1,X2=x2)
}
xgrid=make.grid(x)
ygrid=predict(svmfit,xgrid)
plot(xgrid,col=c("red","blue")[as.numeric(ygrid)],pch=20,cex=.2)
points(x,col=y+3,pch=19)
points(x[svmfit$index,],pch=5,cex=2)
set.seed(10111)
x=matrix(rnorm(40),20,2)
y=rep(c(-1,1),c(10,10))
x[y==1,]=x[y==1,]+1
plot(x,col=y+3,pch=19)
library(e1071)
dat=data.frame(x,y=as.factor(y))
svmfit=svm(y~.,data=dat,kernel="linear",cost=10,scale=FALSE)
print(svmfit)
plot(svmfit,dat)
make.grid=function(x,n=75){
grange=apply(x,2,range)
x1=seq(from=grange[1,1],to=grange[2,1],length=n)
x2=seq(from=grange[1,2],to=grange[2,2],length=n)
expand.grid(X1=x1,X2=x2)
}
xgrid=make.grid(x)
ygrid=predict(svmfit,xgrid)
plot(xgrid,col=c("red","blue")[as.numeric(ygrid)],pch=20,cex=.2)
points(x,col=y+3,pch=19)
points(x[svmfit$index,],pch=5,cex=2)
beta=drop(t(svmfit$coefs)%*%x[svmfit$index,])
beta0=svmfit$rho
plot(xgrid,col=c("red","blue")[as.numeric(ygrid)],pch=20,cex=.2)
points(x,col=y+3,pch=19)
points(x[svmfit$index,],pch=5,cex=2)
abline(beta0/beta[2],-beta[1]/beta[2])
abline((beta0-1)/beta[2],-beta[1]/beta[2],lty=2)
abline((beta0+1)/beta[2],-beta[1]/beta[2],lty=2)
#shuffle data
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
View(dat)
train<-dat[(1:70),]
test[,(1:10)]
trainDat<-dat[(1:70),]
testDat<-dat[(71:100),]
test[,(1:10)]
testDat[,(1:10)]
svmfit=svm(y~.,data=trainDat,kernel="radial",cost=10,scale=FALSE)
predict(svmfit,testDat<-dat[(71:100),])
svmpredict<-predict(svmfit,testDat)
svmpredict$value
svmpredict<-predict(svmfit,testDat[,(1:10)])
svmpredict$value
svmpredict<-predict(svmfit,testDat[,(1:10)])
svmpredict
testError<-svmpredict - testDat$y
testError<-data.frame(svmpredict,testDat$y)
View(testError)
table(svmpredict,testDat$y)
svmpredict<-predict(svmfit,testDat)
table(svmpredict,testDat$y)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
svmSimulation()
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
svmSimulation()
svmSimulation()
testError<-data.frame(svmpredict,testDat$y)
testError$diff = testError$svmpredict == testError$testDat.y
View(dat)
View(testError)
testErrorFrame<-data.frame(svmpredict,testDat$y)
testErrorFrame$diff = testError$svmpredict == testError$testDat.y
testError = sum(testErrorFrame$diff)
table(svmpredict,testDat$y)
testError = sum(testErrorFrame$diff)/30
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
svmSimulation()
svmSimulation()
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
svmSimulation()
svmSimulation()
svmSimulation()
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
svmSimulation()
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
testErrorsMC <- c()
for(i in 1:10){
testErrorsMC[i] <- svmSimulation()
}
mean(testErrorsMC)
for(i in 1:100){
testErrorsMC[i] <- svmSimulation()
}
mean(testErrorsMC)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
View(testDat)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
trainx<-matrix(rnorm(500),100,10)
testx<-matrix(rnorm(500),100,10)
trainy<-rep(c(0,1),c(50,50))
testy<-rep(c(0,1),c(50,50))
#for the indices where y=1, add the vector mu
trainx[trainy==1,]<-trainx[trainy==1,]+c(1,1,1,1,1,0,0,0,0,0)
testx[testy==1,]<-testx[testy==1,]+c(1,1,1,1,1,0,0,0,0,0)
#put all the data together into a dataframe
trainDat<-data.frame(trainx,trainy=as.factor(trainy))
testDat<-data.frame(testx,testy=as.factor(testy))
#shuffle data
#dat<-dat[sample(nrow(dat)),]
#plot first two dimensions
#plot(dat$X1,dat$X2, col=dat$y,pch=19)
#train/test 70/30 split
#trainDat<-dat[(1:70),]
#testDat<-dat[(71:100),]
#fit SVM
svmfit=svm(y~.,data=trainDat,kernel="radial",cost=10,scale=FALSE)
print(svmfit)
#predict on test
svmpredict<-predict(svmfit,testDat[,(1:10)])
View(testDat)
svmpredict<-predict(svmfit,testDat)
svmpredict<-predict(svmfit,testDat[,1:10])
str(trainDat)
str(testDat)
colnames(trainDat)[11] <- "y"
View(trainDat)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
testError = 1 - sum(testErrorFrame$diff)/100
return(testError)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
?svm
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
source('C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/ch9-hwk.R', echo=TRUE)
load("C:/Users/franklin/OneDrive/Documents/r/Stanford Statistical Learning/10.R.RData")
setwd("C:/Users/franklin/Desktop/ATP-Players/Analysis")
source('C:/Users/franklin/Desktop/ATP-Players/Analysis/player_height.R', echo=TRUE)
setwd("C:/Users/franklin/Desktop/ATP-Players")
playerData<-fread("/Data/5_players/player_overviews_UNINDEXED.csv")
playerData<-fread('/Data/5_players/player_overviews_UNINDEXED.csv')
playerData<-fread('Data/5_players/player_overviews_UNINDEXED.csv')
setwd("C:/Users/franklin/Desktop/ATP-Players/Analysis")
playerData<-fread('../Data/5_players/player_overviews_UNINDEXED.csv')
playerDataCol<-fread('../Data/5_players/player_overviews_column_titles.txt',header = TRUE)
View(playerDataCol)
playerDataCol<-fread('../Data/5_players/player_overviews_column_titles.txt',header = FALSE)
colnames(playerData) = c(playerDataCol)
names(playerData) = c(playerDataCol)
playerDataCol<-c(fread('../Data/5_players/player_overviews_column_titles.txt',header = FALSE))
names(playerData) = playerDataCol
setnames(playerData,names(playerData), playerDataCol)
typeof(playerDataCol)
setnames(playerData,names(playerData), unlist(playerDataCol))
View(playerData)
rankingData<-fread('../Data/mergedrankings.csv')
View(rankingData)
rankingData<-fread('../Data/mergedrankings.csv')
rankingData<-fread('../Data/mergedrankings.csv')
rankingData<-fread('../Data/mergedrankings.csv')
View(rankingData)
View(rankingData)
rankingData<-fread('../Data/mergedrankings.csv')
rankingData<-fread('../Data/mergedrankings.csv',check.names = FALSE)
